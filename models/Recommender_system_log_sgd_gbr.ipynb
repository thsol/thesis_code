{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import hour, mean\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Lines Train:  576853\n",
      "No. of Lines Test:  105293\n",
      "No. of Partitions:  2\n"
     ]
    }
   ],
   "source": [
    "path_train = '/Users/tiegsti.solomon/Downloads'\n",
    "path_test = '/Users/tiegsti.solomon/Downloads'\n",
    "\n",
    "# we are taking the training outputs generated by the spark cluster and using the \n",
    "# test data provided by outbrain to validate + compare labels\n",
    "\n",
    "rdd_train = sc.textFile(path_test+\"/content_reco_features_.csv\")\n",
    "rdd_test = sc.textFile(path_train+\"/content_reco_features_test_1.csv\")\n",
    "\n",
    "print \"No. of Lines Train: \", rdd_train.count()\n",
    "print \"No. of Lines Test: \", rdd_test.count()\n",
    "\n",
    "print \"No. of Partitions: \" , rdd_train.getNumPartitions() # 2 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove header train\n",
    "rdd_train_head = rdd_train.filter(lambda l: \"uuid\" in l)\n",
    "rdd_train = rdd_train.subtract(rdd_train_head)\n",
    "\n",
    "# remove header test\n",
    "rdd_test_head = rdd_test.filter(lambda l: \"uuid\" in l)\n",
    "rdd_test = rdd_test.subtract(rdd_test_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_train = rdd_train.map(lambda a: a.split(\",\")).take(100000)\n",
    "rdd_test = rdd_test.map(lambda a: a.split(\",\")).take(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------+--------+---+---+---+-------+---+-----+----+---+---+---+----+---+\n",
      "|            _1|     _2|    _3|      _4| _5| _6| _7|     _8| _9|  _10| _11|_12|_13|_14| _15|_16|\n",
      "+--------------+-------+------+--------+---+---+---+-------+---+-----+----+---+---+---+----+---+\n",
      "|45fd37a633fdfa|1746296|140874| 3644856|  2| US|  1|  47246|  0|14742|2691|  4|  1|  0|   0|  0|\n",
      "|fa58831f4f9c4e|1729862|162985|53650718|  1| US|  1| 827465|  0|15373|2713|  6|  1|  0|   0|  0|\n",
      "|331cfea3ca7148|  60164|124343|31221391|  1| US|  1|2124518|  1|15965|1634|  4|  1|  1|0.25|  1|\n",
      "|807cd39278c64c| 384461|319252|50352702|  2| US|  1| 753836|  1|28971|2635| 10|  1|  1| 0.1|  1|\n",
      "|4536e73cf75581|  60164|152335|53141017|  1| US|  1|6993618|  0|19363|1684|  6|  1|  0|   0|  0|\n",
      "+--------------+-------+------+--------+---+---+---+-------+---+-----+----+---+---+---+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "train_df = sqlContext.createDataFrame(rdd_train) # schema err\n",
    "test_df = sqlContext.createDataFrame(rdd_test)\n",
    "train_df.show(5)\n",
    "\n",
    "df_train = train_df.drop('_4','_14','_15','_16')\n",
    "df_test = test_df.drop('_4','_14','_15','_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "#train_feat = train_df\n",
    "# test_feat = test_df.columns\n",
    "\n",
    "train_dfp = df_train.toPandas()\n",
    "test_dfp =  df_test.toPandas()\n",
    "\n",
    "print(len(train_dfp))\n",
    "print(len(test_dfp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>_3</th>\n",
       "      <th>_5</th>\n",
       "      <th>_6</th>\n",
       "      <th>_7</th>\n",
       "      <th>_8</th>\n",
       "      <th>_9</th>\n",
       "      <th>_10</th>\n",
       "      <th>_11</th>\n",
       "      <th>_12</th>\n",
       "      <th>_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14332</td>\n",
       "      <td>1746296</td>\n",
       "      <td>140874</td>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>47246</td>\n",
       "      <td>0</td>\n",
       "      <td>14742</td>\n",
       "      <td>2691</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61828</td>\n",
       "      <td>1729862</td>\n",
       "      <td>162985</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>827465</td>\n",
       "      <td>0</td>\n",
       "      <td>15373</td>\n",
       "      <td>2713</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9300</td>\n",
       "      <td>60164</td>\n",
       "      <td>124343</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>2124518</td>\n",
       "      <td>1</td>\n",
       "      <td>15965</td>\n",
       "      <td>1634</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29716</td>\n",
       "      <td>384461</td>\n",
       "      <td>319252</td>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>753836</td>\n",
       "      <td>1</td>\n",
       "      <td>28971</td>\n",
       "      <td>2635</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14104</td>\n",
       "      <td>60164</td>\n",
       "      <td>152335</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>6993618</td>\n",
       "      <td>0</td>\n",
       "      <td>19363</td>\n",
       "      <td>1684</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48094</td>\n",
       "      <td>1826941</td>\n",
       "      <td>162984</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>537833</td>\n",
       "      <td>1</td>\n",
       "      <td>15373</td>\n",
       "      <td>2713</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2230</td>\n",
       "      <td>1479631</td>\n",
       "      <td>134758</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>1031635</td>\n",
       "      <td>0</td>\n",
       "      <td>17307</td>\n",
       "      <td>1955</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37304</td>\n",
       "      <td>1790442</td>\n",
       "      <td>60620</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>225382</td>\n",
       "      <td>0</td>\n",
       "      <td>8101</td>\n",
       "      <td>681</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12169</td>\n",
       "      <td>1832504</td>\n",
       "      <td>214724</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>967281</td>\n",
       "      <td>0</td>\n",
       "      <td>24370</td>\n",
       "      <td>1896</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59397</td>\n",
       "      <td>1642428</td>\n",
       "      <td>232313</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>298975</td>\n",
       "      <td>1</td>\n",
       "      <td>25379</td>\n",
       "      <td>3764</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _1       _2      _3 _5   _6 _7       _8 _9    _10   _11 _12 _13\n",
       "0  14332  1746296  140874  2  147  1    47246  0  14742  2691   4   1\n",
       "1  61828  1729862  162985  1  147  1   827465  0  15373  2713   6   1\n",
       "2   9300    60164  124343  1  147  1  2124518  1  15965  1634   4   1\n",
       "3  29716   384461  319252  2  147  1   753836  1  28971  2635  10   1\n",
       "4  14104    60164  152335  1  147  1  6993618  0  19363  1684   6   1\n",
       "5  48094  1826941  162984  1  147  1   537833  1  15373  2713   6   1\n",
       "6   2230  1479631  134758  1  147  1  1031635  0  17307  1955  10   1\n",
       "7  37304  1790442   60620  2  143  1   225382  0   8101   681   5   1\n",
       "8  12169  1832504  214724  3   29  1   967281  0  24370  1896   4   1\n",
       "9  59397  1642428  232313  1  147  1   298975  1  25379  3764   6   1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(train_dfp['_6'].values)\n",
    "train_dfp['_6'] = le.transform(train_dfp['_6'])\n",
    "le.fit(train_dfp['_1'].values)\n",
    "train_dfp['_1'] = le.transform(train_dfp['_1'])\n",
    "\n",
    "le.fit(test_dfp['_6'].values)\n",
    "test_dfp['_6'] = le.transform(test_dfp['_6'])\n",
    "le.fit(test_dfp['_1'].values)\n",
    "test_dfp['_1'] = le.transform(test_dfp['_1'])\n",
    "train_dfp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "train_targets = train_dfp['_9']\n",
    "\n",
    "train_df_ = train_dfp.drop('_9', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combined Features\n",
    "\n",
    "# combine ad_id - page view count per unique user\n",
    "train_df_['_14'] = train_df_.apply(lambda x:'%s%s' % (x['_2'],x['_12']),axis=1)\n",
    "# doc_id - page view count per uuid\n",
    "train_df_['_15'] = train_df_.apply(lambda x:'%s%s' % (x['_3'],x['_12']),axis=1)\n",
    "# platform and traffic source\n",
    "train_df_['_16'] = train_df_.apply(lambda x:'%s%s' % (x['_5'],x['_7']),axis=1) \n",
    "# camapign id advertiser id \n",
    "train_df_['_17'] = train_df_.apply(lambda x:'%s%s' % (x['_10'],x['_11']),axis=1)\n",
    "# geo_location , traffic source\n",
    "train_df_['_18'] = train_df_.apply(lambda x:'%s%s' % (x['_6'],x['_7']),axis=1) \n",
    "# campaign id + page view\n",
    "train_df_['_19'] = train_df_.apply(lambda x:'%s%s' % (x['_10'],x['_12']),axis=1) \n",
    "# geo + pv\n",
    "train_df_['_20'] = train_df_.apply(lambda x:'%s%s' % (x['_6'],x['_12']),axis=1) \n",
    "# platform + pv\n",
    "train_df_['_21'] = train_df_.apply(lambda x:'%s%s' % (x['_5'],x['_12']),axis=1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test data replicate\n",
    "test_dfp['_14'] = test_dfp.apply(lambda x:'%s%s' % (x['_2'],x['_12']),axis=1)\n",
    "test_dfp['_15'] = test_dfp.apply(lambda x:'%s%s' % (x['_3'],x['_12']),axis=1)\n",
    "test_dfp['_16'] = test_dfp.apply(lambda x:'%s%s' % (x['_5'],x['_7']),axis=1) \n",
    "test_dfp['_17'] = test_dfp.apply(lambda x:'%s%s' % (x['_10'],x['_11']),axis=1) \n",
    "test_dfp['_18'] = test_dfp.apply(lambda x:'%s%s' % (x['_6'],x['_7']),axis=1)\n",
    "test_dfp['_19'] = test_dfp.apply(lambda x:'%s%s' % (x['_10'],x['_12']),axis=1)\n",
    "test_dfp['_20'] = test_dfp.apply(lambda x:'%s%s' % (x['_6'],x['_12']),axis=1)\n",
    "test_dfp['_21'] = test_dfp.apply(lambda x:'%s%s' % (x['_5'],x['_12']),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log=LogisticRegression(penalty='l1',C=1.0)\n",
    "log.fit(train_df_, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_dfp = test_dfp.convert_objects(convert_numeric=True)\n",
    "test_dfp = test_dfp.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Score LR: ', 0.65014000000000005)\n",
      "('Cross Entropy LR: ', 0.50882068596457908)\n",
      "('Confusion Matrix LR: ', array([[60024, 20949],\n",
      "       [14037,  4990]]))\n",
      "('Classification Report: ', u'             precision    recall  f1-score   support\\n\\n          0       0.81      0.74      0.77     80973\\n          1       0.19      0.26      0.22     19027\\n\\navg / total       0.69      0.65      0.67    100000\\n')\n",
      "('Mean Squared Error: ', 0.19026999999999999)\n",
      "('Root Mean Squared Error: ', 0.4361994956439083)\n"
     ]
    }
   ],
   "source": [
    "y_pred = log.predict(test_dfp)\n",
    "\n",
    "predicted_rel_prob = log.predict_proba(test_dfp)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "y_pred_mod = []\n",
    "\n",
    "for i in predicted_rel_prob:\n",
    "    if i[1] >= 0.3:\n",
    "        y_pred_mod.append('1')\n",
    "    else:\n",
    "        y_pred_mod.append('0')\n",
    "        \n",
    "y_pred_mod = np.array(y_pred_mod)\n",
    "\n",
    "print(\"Accuracy Score LR: \", accuracy_score(train_targets, y_pred_mod))\n",
    "print(\"Cross Entropy LR: \", log_loss(train_targets, predicted_rel_prob))\n",
    "\n",
    "print(\"Confusion Matrix LR: \", confusion_matrix(train_targets, y_pred_mod))\n",
    "print(\"Classification Report: \", metrics.classification_report(train_targets, y_pred_mod))\n",
    "mean_squared_err = mean_squared_error(train_targets, y_pred)\n",
    "print(\"Mean Squared Error: \", mean_squared_err)\n",
    "print(\"Root Mean Squared Error: \", sqrt(mean_squared_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1.0, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l1', power_t=0.5, random_state=0, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l1\")\n",
    "clf.fit(train_df_, train_targets)\n",
    "SGDClassifier(alpha=1.0, average=False, learning_rate='optimal',\n",
    "              class_weight=None, epsilon=0.1,\n",
    "              fit_intercept=True, l1_ratio=0.15, eta0=0.0,\n",
    "              loss='log', max_iter=5, n_iter=None,\n",
    "              n_jobs=1, penalty='l1', power_t=0.5,\n",
    "              random_state=0,\n",
    "              tol=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Score SGD: ', 0.71079000000000003)\n",
      "('Cross Entropy SGD: ', 9.9889595211722408)\n",
      "('Confusion Matrix SGD: ', array([[68025, 12948],\n",
      "       [15973,  3054]]))\n",
      "('Classification Report SGD: ', u'             precision    recall  f1-score   support\\n\\n          0       0.81      0.84      0.82     80973\\n          1       0.19      0.16      0.17     19027\\n\\navg / total       0.69      0.71      0.70    100000\\n')\n",
      "('Mean Squared Error: ', 0.28921000000000002)\n",
      "('Root Mean Squared Error: ', 0.5377824839096194)\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = clf.predict(test_dfp)\n",
    "y_pred_proba = clf.predict_proba(test_dfp)\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "print(\"Accuracy Score SGD: \", accuracy_score(train_targets, y_pred2))\n",
    "print(\"Cross Entropy SGD: \", log_loss(train_targets, y_pred_proba))\n",
    "print(\"Confusion Matrix SGD: \", confusion_matrix(train_targets, y_pred2))\n",
    "print(\"Classification Report SGD: \", metrics.classification_report(train_targets, y_pred2))\n",
    "mean_squared_err = mean_squared_error(train_targets, [float(i) for i in y_pred2])\n",
    "print(\"Mean Squared Error: \", mean_squared_err)\n",
    "print(\"Root Mean Squared Error: \", sqrt(mean_squared_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBR\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "params = {'n_estimators': 100, 'max_depth': 6,\n",
    "        'learning_rate': 0.1, 'alpha':0.98}\n",
    "gbr = GradientBoostingRegressor(**params).fit(train_df_, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "y_pred3 = gbr.predict(test_dfp)\n",
    "#y_pred_proba2 = gbr.predict_proba(test_dfp)\n",
    "y_pred3_mod = []\n",
    "\n",
    "for i in y_pred3:\n",
    "    if i >= 0.3:\n",
    "        y_pred3_mod.append('1')\n",
    "    else:\n",
    "        y_pred3_mod.append('0')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Score GBR: ', 0.57835999999999999)\n",
      "('Cross Entropy GBR: ', 0.63912518740306234)\n",
      "('Confusion Matrix GBR: ', array([[50736, 30237],\n",
      "       [11927,  7100]]))\n",
      "('Classification Report GBR: ', u'             precision    recall  f1-score   support\\n\\n          0       0.81      0.63      0.71     80973\\n          1       0.19      0.37      0.25     19027\\n\\navg / total       0.69      0.58      0.62    100000\\n')\n",
      "('Mean Squared Error: ', 0.18066030936470365)\n",
      "('Root Mean Squared Error: ', 0.42504153839913533)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score GBR: \", accuracy_score(train_targets, y_pred3_mod))\n",
    "print(\"Cross Entropy GBR: \", log_loss(train_targets, y_pred3))\n",
    "print(\"Confusion Matrix GBR: \", confusion_matrix(train_targets, y_pred3_mod))\n",
    "print(\"Classification Report GBR: \", metrics.classification_report(train_targets, y_pred3_mod))\n",
    "mean_squared_err = mean_squared_error(train_targets, y_pred3)\n",
    "print(\"Mean Squared Error: \", mean_squared_err)\n",
    "print(\"Root Mean Squared Error: \", sqrt(mean_squared_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[60024 20949]\n",
      " [14037  4990]]\n",
      "Normalized confusion matrix\n",
      "[[ 0.74128413  0.25871587]\n",
      " [ 0.7377411   0.2622589 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/matplotlib/tight_layout.py:225: UserWarning: tight_layout : falling back to Agg renderer\n",
      "  warnings.warn(\"tight_layout : falling back to Agg renderer\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "X = train_df_\n",
    "y_true = train_targets\n",
    "class_names = [0,1]\n",
    "\n",
    "test_targets = test_dfp['_9']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    \n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(train_targets, y_pred_mod)    \n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "\n",
    "# # evenly sampled time at 200ms intervals\n",
    "lr_acc = [0,0.52,0.63,0.64]\n",
    "gbr_acc = [0,0.31,0.51,0.59]\n",
    "sgd_acc = [0,0.61,0.81,0.81]\n",
    "lr_logloss = [0,0.53,0.51,0.51]\n",
    "gbr_logloss = [0,0.88,0.59,0.62]\n",
    "sgd_logloss = [0,6.65,6.61,13.18]\n",
    "x = np.array([0,10000,50000,100000])\n",
    "\n",
    "# x_smooth = np.linspace(x.min(),x.max())\n",
    "# y_smooth_lr_acc = spline(x,lr_acc,x_smooth)\n",
    "# y_smooth_gbr_acc = spline(x,gbr_acc,x_smooth)\n",
    "# y_smooth_sgd_acc = spline(x,sgd_acc,x_smooth)\n",
    "\n",
    "# Accuracy \n",
    "plt.xlabel('Training Set (No. of rows)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(x, lr_acc, 'rs-', x, gbr_acc, 'b^-', x, sgd_acc, 'go-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy\n",
    "\n",
    "predicted_rel_prob_samp = predicted_rel_prob[0:100]\n",
    "y_pred3_samp = y_pred3[0:100]\n",
    "y_pred2_samp = y_pred_proba[0:100]\n",
    "\n",
    "y_lr = np.array([i[1] for i in predicted_rel_prob_samp])\n",
    "y_gbr = np.array(y_pred3_samp)\n",
    "y_sgd = np.array(y_pred2_samp)\n",
    "\n",
    "#x_smooth_lr = np.linspace(x_lr.min(),x_lr.max())\n",
    "#x_smooth_gbr = np.linspace(x_gbr.min(),x_gbr.max())\n",
    "#x_smooth_sgd = np.linspace(x_sgd.min(),x_sgd.max())\n",
    "\n",
    "x = np.arange(0.0,1.0,0.01)\n",
    "# y_smooth_lr_logloss = spline(x,x_lr,x_lr)\n",
    "# y_smooth_gbr_logloss = spline(x,x_gbr,x_smooth_gbr)\n",
    "# y_smooth_sgd_logloss = spline(x,x_sgd,x_smooth_sgd)\n",
    "\n",
    "plt.xlabel('Probability (1)')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([-0.5,1.5])\n",
    "\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(x, y_lr, 'r-', x, y_gbr, 'b-', x, y_sgd, 'g-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC(label,result):\n",
    "    %matplotlib inline\n",
    "    from sklearn.utils import shuffle\n",
    "    from sklearn.metrics import roc_curve, auc, precision_score, roc_auc_score\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    import pylab as pl\n",
    "    import numpy as py\n",
    "    Y = np.array(label)\n",
    "    truth = label_binarize(label, classes=[0,1])\n",
    "    n_classes = truth.shape[1]\n",
    "    pred = label_binarize(result, classes=[0,1])\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(truth[:, i], pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "    # Plot of a ROC curve for a specific class\n",
    "    pl.figure()\n",
    "    pl.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "    pl.plot([0, 1], [0, 1], 'k--')\n",
    "    pl.xlim([0.0, 1.0])\n",
    "    pl.ylim([0.0, 1.05])\n",
    "    pl.xlabel('FP')\n",
    "    pl.ylabel('TP')\n",
    "    pl.legend(loc=\"lower right\")\n",
    "    pl.show()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        pl.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                       ''.format(i, roc_auc[i]))\n",
    "\n",
    "    pl.plot([0, 1], [0, 1], 'k--')\n",
    "    pl.xlim([0.0, 1.0])\n",
    "    pl.ylim([0.0, 1.05])\n",
    "    pl.xlabel('FP')\n",
    "    pl.ylabel('TP')\n",
    "    pl.legend(loc=\"lower right\")\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "ROC(train_targets[:], y_pred2[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
